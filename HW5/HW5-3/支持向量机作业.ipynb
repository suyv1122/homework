{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 问答题\n",
    "1. 支持向量机的基本思想是什么？\n",
    "\n",
    "2. 什么是支持向量？\n",
    "\n",
    "3. 在使用 SVM 时，缩放输入值为什么很重要？\n",
    "\n",
    "4. SVM 分类器在对实例进行分类时能输出置信度分数吗？概率呢？\n",
    "\n",
    "5. 你如何在 LinearSVC、SVC 和 SGDClassifier 之间进行选择？\n",
    "\n",
    "6. 假设你已经使用 RBF 核训练了一个 SVM 分类器，但它似乎欠拟合训练集。\n",
    "   你应该增大还是减小 γ（gamma）？C 呢？\n",
    "\n",
    "7. ε 不敏感模型是什么意思？\n",
    "\n",
    "8. 使用核技巧有什么意义？"
   ],
   "id": "a0b8b340a137572d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 编程题\n",
    "1. 在葡萄酒数据集上训练SVM分类器，可以使用sklearn.datasets.load_wine()加载它。该数据集包含3个不同种植者生产的178个葡萄酒样本的化学分析：目标是训练一个分类模型，该模型能够根据葡萄酒的化学分析预测种植者。由于SVM分类器是二元分类器，将需要使用“一对全部”对所有三个类进行分类。能达到的精度是多少？\n",
    "\n",
    "   \"一对全部\"可以复习 **8_sklearn做分类.ipynb**里的笔记，里面提到了用二元分类器做多分类问题\n",
    "\n",
    "---\n",
    "\n",
    "2. 提前预习 **10_支持向量机.ipynb** 最新更新的笔记 （把SVM分类用梯度下降实现）； 大概理解笔记后，尝试自己对照笔记 实现用梯度下降实现SVM分类\n",
    "\n",
    "   并把自定义的SVM分类用于 iris data(鸢尾花数据)； 取花瓣长度 和 花瓣宽度特征， 分类 看是不是 分类2的花 （(iris.target == 2)\n",
    "\n",
    "   对比下sklearn自带的SVM分类 和 自定义SVM分类 实现的分类效果\n",
    "\n",
    "---\n",
    "\n",
    "3. 在加州房屋数据集上训练和微调SVM回归器。可以使用原始数据集而不是 在课上使用的调整后的版本，\n",
    "可以使用sklearn.datasets.fetch_california_housing()加载它。目标代表了数十万美元。\n",
    "由于有超过20000个实例，SVM可能会很慢，因此对于超参数调整，应该使用更少的实例（例如2000个）来测试更多的超参数组合。最佳模型的RMSE是多少？\n"
   ],
   "id": "f5a1dfdea31badc1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-11T11:22:20.505452Z",
     "start_time": "2025-08-11T11:22:20.484134Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "base_data = fetch_california_housing(as_frame=True)\n",
    "data = base_data.frame\n",
    "data.info()"
   ],
   "id": "9b8003a869951932",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   MedInc       20640 non-null  float64\n",
      " 1   HouseAge     20640 non-null  float64\n",
      " 2   AveRooms     20640 non-null  float64\n",
      " 3   AveBedrms    20640 non-null  float64\n",
      " 4   Population   20640 non-null  float64\n",
      " 5   AveOccup     20640 non-null  float64\n",
      " 6   Latitude     20640 non-null  float64\n",
      " 7   Longitude    20640 non-null  float64\n",
      " 8   MedHouseVal  20640 non-null  float64\n",
      "dtypes: float64(9)\n",
      "memory usage: 1.4 MB\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-11T11:22:37.477843Z",
     "start_time": "2025-08-11T11:22:20.516201Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 没有缺失值 全部数据为数值类型\n",
    "\n",
    "# 分层采样 特征分离\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, RandomizedSearchCV\n",
    "# data.data\n",
    "# data.target.name\n",
    "data['MedInc_cut'] = pd.cut(data['MedInc'],\n",
    "                               bins= [0., 1.5, 3., 4.5, 6., np.inf],\n",
    "                               labels = [1,2,3,4,5])\n",
    "split = StratifiedShuffleSplit(n_splits = 3, test_size = 0.2, random_state = 35)\n",
    "for train_index, test_index in split.split(data, data['MedInc_cut']):\n",
    "    strat_train_set = data.loc[train_index]\n",
    "    strat_test_set = data.loc[test_index]\n",
    "\n",
    "X_train = strat_train_set.drop(base_data.target.name, axis=1)\n",
    "y_train = strat_train_set[base_data.target.name]\n",
    "X_test = strat_test_set.drop(base_data.target.name, axis=1)\n",
    "y_test = strat_test_set[base_data.target.name]\n",
    "\n",
    "# 丢掉辅助列\n",
    "for train_index, test_index in split.split(data, data['MedInc_cut']):\n",
    "    strat_train_set = data.loc[train_index].drop('MedInc_cut', axis=1)\n",
    "    strat_test_set = data.loc[test_index].drop('MedInc_cut', axis=1)\n",
    "\n",
    "\n",
    "# 数据归一化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_prepared = scaler.fit_transform(X_train)\n",
    "X_test_prepared = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# 限制搜寻范围 这部分来自gpt\n",
    "n_search = 2000  # 搜索子集大小\n",
    "rng = np.random.RandomState(42)\n",
    "idx = rng.choice(len(X_train), size=min(n_search, len(X_train)), replace=False)\n",
    "\n",
    "X_train_sub = X_train_prepared[idx]\n",
    "y_train_sub = y_train.iloc[idx]\n",
    "\n",
    "\n",
    "\n",
    "# 模型训练与调参\n",
    "from sklearn.svm import SVR\n",
    "SVR_model = SVR()\n",
    "param_distributions = {\n",
    "    'kernel': ['rbf', 'linear'],\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale','auto', 0.01, 0.001],\n",
    "    'epsilon': [0.001, 0.1, 0.2, 0.5]}\n",
    "grid_search = RandomizedSearchCV(SVR_model, param_distributions, cv=5,\n",
    "                           scoring='neg_mean_squared_error',\n",
    "                           return_train_score=True, n_iter = 20, n_jobs=-1, random_state=42)\n",
    "grid_search.fit(X_train_sub, y_train_sub)\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "# 效率验证部分\n",
    "from sklearn.metrics import mean_squared_error\n",
    "final_predictions = best_model.predict(X_test_prepared)\n",
    "final_rmse =np.sqrt(mean_squared_error(y_test, final_predictions))\n",
    "best_score = grid_search.best_score_\n",
    "best_cv_rmse = np.sqrt(-best_score)\n",
    "print(\"预测值:\", final_predictions[:5])\n",
    "print(\"实际值:\", y_test.values[:5])\n",
    "print(\"finalRMSE:\", final_rmse, \"|\", \"Best CV RMSE:\",best_cv_rmse)"
   ],
   "id": "44e2438b2e471282",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测值: [0.93462758 3.24924147 2.56259548 2.01626802 2.74917228]\n",
      "实际值: [0.855 3.881 2.75  2.613 3.5  ]\n",
      "finalRMSE: 0.623099373931964 | Best CV RMSE: 0.6645780449460803\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-11T11:32:01.102021Z",
     "start_time": "2025-08-11T11:31:49.915492Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# gpt给出的管道封装版本，留作模板\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # 数据标准化\n",
    "    ('svr', SVR())                 # SVM 回归\n",
    "])\n",
    "\n",
    "# 6. 定义超参数搜索范围（注意：使用 'svr__' 前缀）\n",
    "param_distributions = {\n",
    "    'svr__kernel': ['rbf', 'linear'],\n",
    "    'svr__C': [0.1, 1, 10, 100],\n",
    "    'svr__gamma': ['scale', 'auto', 0.01, 0.001],\n",
    "    'svr__epsilon': [0.001, 0.1, 0.2, 0.5]\n",
    "}\n",
    "\n",
    "# 7. 随机搜索\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=20,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "search.fit(X_train_sub, y_train_sub)\n",
    "\n",
    "# 8. 最佳模型\n",
    "best_model = search.best_estimator_\n",
    "print(\"Best parameters:\", search.best_params_)\n",
    "\n",
    "# 9. 在完整测试集上评估\n",
    "final_predictions = best_model.predict(X_test_prepared)\n",
    "final_rmse = np.sqrt(mean_squared_error(y_test, final_predictions))\n",
    "print(\"Final RMSE:\", final_rmse)"
   ],
   "id": "314111a6d5a00360",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'svr__kernel': 'rbf', 'svr__gamma': 'scale', 'svr__epsilon': 0.2, 'svr__C': 10}\n",
      "Final RMSE: 0.617684925915562\n"
     ]
    }
   ],
   "execution_count": 50
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
